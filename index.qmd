---
title: "Nonprofessional Translators in the Age of AI: Exploring Translator Aptitude and   
Human-Computer Interaction"
subtitle: "Dissertation Proposal"
author: "Stephanie A. Rodríguez"
institute: "Rutgers University"
date: "Last update: `r Sys.Date()`"
format: rutgers-revealjs
engine: knitr
execute: 
  out.width: "100%"
  fig.asp: 0.5625
  dpi: 300
---

## Today's Overview
- Why this study?
- What is "Translation Aptitude"?
- Who are "Non-professional translators"?
- How do language use and perception shape aptitude?
- How is the study designed to test these questions?
- What does this dissertation contribute? 

## Overall Aims 

**The project has two primary aims:**

(1) To examine the translation aptitude of Spanish-English bilinguals who act as nonprofessional translators, specifically language brokers, in the AI era; 

(2) To better understand the human-computer interaction of nonprofessional translators with LLMs, focusing on task delegation patterns, prompt engineering strategies, and natural post editing ability. 

## Foundations of Translation Ability

- **Translation Aptitude** is a natural human capacity for overcoming communication barriers (Whyatt, 2017).

- Angelelli (2009) designed rubric to assess translation and measure translation ability.

- **Translation Competence** is “the underlying system of knowledge and skills needed to be able to translate” (PACTE, 2000, p. 100).

## Who are Non-professional Translators? 

- **Natural Translation** (Harris and Sherwood, 1978) or **Non-professional Translation** (Antonini, 2017) performed in everyday circumstances by bilinguals who are untrained. 

- **Language brokers** are bilinguals who translate and/or interpret within their communities (Tse, 1995).

- U.S. Context: growth of Spanish-speaking communities has increased the number of heritage Spanish speakers (Lozano-Argüelles & Martínez-Gómez, 2025, many of whom broker language in daily life (Martínez-Gómez, 2021).

## Language Use and Development

:::{.columns}
::: {.column width="65%"}

**HL speakers show** reduced metalinguistic awareness and literacy in the heritage language (Montrul, 2022; Polinsky, 2023).

**Language brokers show:**
<small>

- Enhanced lexical/semantic processing (García et al., 2014)
- Stronger problem-solving skills (López et al., 2019)
- Faster validation of idiomatic renderings (Vaid & López, 2014)
- Greater convergence across languages

</small>

:::
::: {.column width="35%"}

**Strategies:**

- Borrowing
- Calquing
- Circumlocution

:::
:::

## Language Perception 

- HL speakers reported lower confidence in their Spanish abilities, even when their proficiency is high (Lozano-Argüelles, 2023). 

- More brokering experience contributed to confidence in both languages (López et al., 2019)

- Brokering experience perceived to help maintain HL Spanish proficiency (Kim et al., 2024). 

## Translation Technologies

- **Technological Turn** has occurred in translation, resulting in human–computer interaction (HCI) (Jiménez-Crespo, 2020)

- **HCI** is the interaction between people, computers, and tasks (O'Brien, 2012)

- With **Intelligence amplification (IA)** humans remain the central decision-makers and AI is a tools (Shneiderman, 2022)

- MT use is increasing (~1B users), yet few users have formal translation training (~0.03%) (Nurminen, 2021)

- Nonprofessional translators a major user group and report needing AI literacy (Bowker, 2025)

## Task Delegation and Prompt Behavior

:::{.columns}
::: {.column width="45%"}

**Task Delegation**
<small>

- *Transfer* and *revision* are the most frequently delegated tasks
- Observed behaviors reflect intuitive and uninformed practices (Zhang et al., 2025)

</small>


:::
::: {.column width="55%"}

**Prompting Behavior**
<small>

- Included bilingual input, typographical errors, and colloquialisms
- Frequently lacked explicit task descriptions or contextual information
- Many sessions ended after a single round of prompting
- ChatGPT performance improves when prompts include context and chain-of-thought guidance (Lu et al., 2023)

</small>

:::
:::

## Post Editing of Machine Translation

<div style="font-size:0.8em;">

- Untrained participants struggled to detect and correct MT errors (Zhang & Torres-Hostench, 2022).
- Untrained participants failed to identify or correct errors related to cultural references, metaphorical expressions, or punctuation (Zhan & Hsu, 2024).
- Syntactic errors were more readily identified and corrected, while errors involving lexical or syntactic ambiguity were less consistently detected (Kim, 2025).
- Most frequently overlooked errors included accuracy, word order, official names, preposition choice, omissions, and formal register.

</div>

## Motivation 
* Limited research on nonprofessional translators’ translation performance, particularly language brokers.

* Limited research on how nonprofessional translators post-edit LLM output.

* No existing research examining language brokers’ HCI with LLMs (task delegation, prompting, and post-editing).

## Adapted Translator Measurement 
![](images/table1.png){width=70%}

## Participants 
A minimum of 60 adult Spanish-English bilinguals.

*Requirement to participate:* 

(1) 18 years of age or older, 
(2) Born and/or raised in the United States, 
(3) Grown up speaking Spanish at home, 
(4) Currently reside in the United States, and 
(5) History of language brokering in childhood or adolescence. 

## Study 1
<span style="font-size: 0.8em;"> **Goal:** Examine participants bilingual proficiency, AI use, and language brokering experience.

### Research Questions 
<span style="font-size: 0.8em;">
1. What are the language backgrounds of participants, and how do these relate to their language proficiency as measured by LexTALE-Eng and LexTALE-Esp?   

<span style="font-size: 0.8em;">
2. How do participants perceive the role of language brokering in their bilingual development and heritage language maintenance?    

<span style="font-size: 0.8em;">
3. How do participants use AI, specifically LLMs, when language brokering?

## Materials 

<div style="font-size:0.9em;">

- **Bilingualism, Brokering, and AI-Translation Questionnaire**
  - *Part 1:* Adapted LHQ-3 (Li et al., 2020) and LEAP-Q (Marian et al., 2007)
  - *Part 2:* Language brokering experience (Lozano-Argüelles & Martínez-Gómez, 2025)
  - *Part 3:* AI use (Dorst et al., 2025; Zhang & Doherty, 2025)
- **LexTALE – Spanish** (Izura et al., 2014)
- **LexTALE – English** (Lemhöfer & Broersma, 2012)

</div>


## Statistical Analysis 

**LexTALE scores:**
  Linear mixed-effects regression model (lmer/ (Bates et    al., 2015), lmerTest (Kuznetsova et al., 2017)
  
**Open-ended responses:**
  Coded using thematic content analysis
  (Braun & Clarke, 2006)
  
## Study 2
<span style="font-size: 0.8em;"> **Goal:** Examine participants natural translation ability.

### Research Questions 
<span style="font-size: 0.8em;">
1. Which semantic and pragmatic features (e.g., register, cognates, idiomatic phrases) are most prone to error in the translations produced by participants?    

<span style="font-size: 0.8em;">
2. How does brokering experience relate to participants’ handling of semantic-pragmatic features during translation?     

<span style="font-size: 0.8em;">
3. How does bilingual language proficiency (bidirectional) based on the LexTALE, correlate with participants’ translation performance?  

## Materials 

:::{.columns}
::: {.column width="45%"}

**Forced Choice Cognate Task** 

<small>

  - Identify and select context-appropriate meanings for    Spanish-English cognates

</small>

![](images/task1.png){width=70%}

:::
::: {.column width="55%"}

**Human Translation Task**
<small>

  - 1 English into Spanish translation task and 1 Spanish     into English translation task (150-word text)

</small>

![](images/task2.png){width=70%}

:::
:::
  
## Statistical Analysis 
Generalized linear mixed-effects (GLMMs) 

**Forced Choice Cognate Task**

  - Code for accuracy 
  
**Human Translation Task** 

  - Coding: Segment-level error annotation 
    (Calques, false cognates, literal renderings)

## Study 3
<span style="font-size: 0.8em;"> **Goal:** Examine participants human-computer interaction. 

### Research Questions 
<span style="font-size: 0.8em;">
1. What translation tasks do participants outsource to LLMs?     

<span style="font-size: 0.8em;">
2. How do participants linguistically structure their prompts when interacting with LLMs, and which prompt engineering strategies are used?    

<span style="font-size: 0.8em;">
3. How effectively do participants identify and correct errors in LLM-generated translations, and which types of errors are most and least frequently detected during post-editing?  

## Materials

- **Human-Computer Interaction Task**

  - Translate document (250 words) into Spanish using an     LLM, specifically ChatGPT. 

- **Post-editing of MT Task**

  - Post-edit English into Spanish AI-generated              translation (200 words).
  
## Data Coding 

::: columns
::: column
![](images/figure1.png){height=400px}
:::

::: column
![](images/figure2.png){height=400px}
:::
:::

## Data Analysis 
![](images/table2.png){width=90%}

## Statistical Analysis 

Mixed methods: qualitative + quantitative analyses

**Task Delegation**

  - Code using Translation Tasks Typology 
  
**Prompt Engineering**

  - Code using LLM Prompting Strategies and Discourse        Features

## 
::: {.hide-title}
:::

<div style="text-align:center;">

**Thank you!** 

<br>

**¡Gracias!**

<br>

![](images/image1.png){width=25%}


<em>How can we better understand the translation aptitude of nonprofessional translators in the age of AI?</em>

</div>


